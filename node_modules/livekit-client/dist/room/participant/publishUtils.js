"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.sortPresets = exports.defaultSimulcastLayers = exports.presetsForResolution = exports.determineAppropriateEncoding = exports.computeVideoEncodings = exports.computeDefaultScreenShareSimulcastPresets = exports.defaultSimulcastPresets43 = exports.defaultSimulcastPresets169 = exports.presetsScreenShare = exports.presets43 = exports.presets169 = exports.mediaTrackToLocalTrack = void 0;
const logger_1 = __importDefault(require("../../logger"));
const errors_1 = require("../errors");
const LocalAudioTrack_1 = __importDefault(require("../track/LocalAudioTrack"));
const LocalVideoTrack_1 = __importDefault(require("../track/LocalVideoTrack"));
const options_1 = require("../track/options");
/** @internal */
function mediaTrackToLocalTrack(mediaStreamTrack, constraints) {
    switch (mediaStreamTrack.kind) {
        case 'audio':
            return new LocalAudioTrack_1.default(mediaStreamTrack, constraints);
        case 'video':
            return new LocalVideoTrack_1.default(mediaStreamTrack, constraints);
        default:
            throw new errors_1.TrackInvalidError(`unsupported track type: ${mediaStreamTrack.kind}`);
    }
}
exports.mediaTrackToLocalTrack = mediaTrackToLocalTrack;
/* @internal */
exports.presets169 = Object.values(options_1.VideoPresets);
/* @internal */
exports.presets43 = Object.values(options_1.VideoPresets43);
/* @internal */
exports.presetsScreenShare = Object.values(options_1.ScreenSharePresets);
/* @internal */
exports.defaultSimulcastPresets169 = [
    options_1.VideoPresets.h180,
    options_1.VideoPresets.h360,
];
/* @internal */
exports.defaultSimulcastPresets43 = [
    options_1.VideoPresets43.h180,
    options_1.VideoPresets43.h360,
];
/* @internal */
const computeDefaultScreenShareSimulcastPresets = (fromPreset) => {
    const layers = [{ scaleResolutionDownBy: 2, fps: 3 }];
    return layers.map((t) => {
        var _a;
        return new options_1.VideoPreset(Math.floor(fromPreset.width / t.scaleResolutionDownBy), Math.floor(fromPreset.height / t.scaleResolutionDownBy), Math.max(150000, Math.floor(fromPreset.encoding.maxBitrate
            / (Math.pow(t.scaleResolutionDownBy, 2) * (((_a = fromPreset.encoding.maxFramerate) !== null && _a !== void 0 ? _a : 30) / t.fps)))), t.fps);
    });
};
exports.computeDefaultScreenShareSimulcastPresets = computeDefaultScreenShareSimulcastPresets;
const videoRids = ['q', 'h', 'f'];
/* @internal */
function computeVideoEncodings(isScreenShare, width, height, options) {
    var _a, _b;
    let videoEncoding = options === null || options === void 0 ? void 0 : options.videoEncoding;
    if (isScreenShare) {
        videoEncoding = options === null || options === void 0 ? void 0 : options.screenShareEncoding;
    }
    const useSimulcast = options === null || options === void 0 ? void 0 : options.simulcast;
    if ((!videoEncoding && !useSimulcast) || !width || !height) {
        // when we aren't simulcasting, will need to return a single encoding without
        // capping bandwidth. we always require a encoding for dynacast
        return [{}];
    }
    if (!videoEncoding) {
        // find the right encoding based on width/height
        videoEncoding = determineAppropriateEncoding(isScreenShare, width, height);
        logger_1.default.debug('using video encoding', videoEncoding);
    }
    if (!useSimulcast) {
        return [videoEncoding];
    }
    const original = new options_1.VideoPreset(width, height, videoEncoding.maxBitrate, videoEncoding.maxFramerate);
    let presets = [];
    if (isScreenShare) {
        presets = (_a = sortPresets(options === null || options === void 0 ? void 0 : options.screenShareSimulcastLayers)) !== null && _a !== void 0 ? _a : defaultSimulcastLayers(isScreenShare, original);
    }
    else {
        presets = (_b = sortPresets(options === null || options === void 0 ? void 0 : options.videoSimulcastLayers)) !== null && _b !== void 0 ? _b : defaultSimulcastLayers(isScreenShare, original);
    }
    let midPreset;
    const lowPreset = presets[0];
    if (presets.length > 1) {
        [, midPreset] = presets;
    }
    // NOTE:
    //   1. Ordering of these encodings is important. Chrome seems
    //      to use the index into encodings to decide which layer
    //      to disable when CPU constrained.
    //      So encodings should be ordered in increasing spatial
    //      resolution order.
    //   2. ion-sfu translates rids into layers. So, all encodings
    //      should have the base layer `q` and then more added
    //      based on other conditions.
    const size = Math.max(width, height);
    if (size >= 960 && midPreset) {
        return encodingsFromPresets(width, height, [
            lowPreset, midPreset, original,
        ]);
    }
    if (size >= 480) {
        return encodingsFromPresets(width, height, [
            lowPreset, original,
        ]);
    }
    return encodingsFromPresets(width, height, [
        original,
    ]);
}
exports.computeVideoEncodings = computeVideoEncodings;
/* @internal */
function determineAppropriateEncoding(isScreenShare, width, height) {
    const presets = presetsForResolution(isScreenShare, width, height);
    let { encoding } = presets[0];
    // handle portrait by swapping dimensions
    const size = Math.max(width, height);
    for (let i = 0; i < presets.length; i += 1) {
        const preset = presets[i];
        encoding = preset.encoding;
        if (preset.width >= size) {
            break;
        }
    }
    return encoding;
}
exports.determineAppropriateEncoding = determineAppropriateEncoding;
/* @internal */
function presetsForResolution(isScreenShare, width, height) {
    if (isScreenShare) {
        return exports.presetsScreenShare;
    }
    const aspect = width > height ? width / height : height / width;
    if (Math.abs(aspect - 16.0 / 9) < Math.abs(aspect - 4.0 / 3)) {
        return exports.presets169;
    }
    return exports.presets43;
}
exports.presetsForResolution = presetsForResolution;
/* @internal */
function defaultSimulcastLayers(isScreenShare, original) {
    if (isScreenShare) {
        return exports.computeDefaultScreenShareSimulcastPresets(original);
    }
    const { width, height } = original;
    const aspect = width > height ? width / height : height / width;
    if (Math.abs(aspect - 16.0 / 9) < Math.abs(aspect - 4.0 / 3)) {
        return exports.defaultSimulcastPresets169;
    }
    return exports.defaultSimulcastPresets43;
}
exports.defaultSimulcastLayers = defaultSimulcastLayers;
// presets should be ordered by low, medium, high
function encodingsFromPresets(width, height, presets) {
    const encodings = [];
    presets.forEach((preset, idx) => {
        if (idx >= videoRids.length) {
            return;
        }
        const size = Math.min(width, height);
        const rid = videoRids[idx];
        encodings.push({
            rid,
            scaleResolutionDownBy: size / Math.min(preset.width, preset.height),
            maxBitrate: preset.encoding.maxBitrate,
            /* @ts-ignore */
            maxFramerate: preset.encoding.maxFramerate,
        });
    });
    return encodings;
}
/** @internal */
function sortPresets(presets) {
    if (!presets)
        return;
    return presets.sort((a, b) => {
        const { encoding: aEnc } = a;
        const { encoding: bEnc } = b;
        if (aEnc.maxBitrate > bEnc.maxBitrate) {
            return 1;
        }
        if (aEnc.maxBitrate < bEnc.maxBitrate)
            return -1;
        if (aEnc.maxBitrate === bEnc.maxBitrate && aEnc.maxFramerate && bEnc.maxFramerate) {
            return aEnc.maxFramerate > bEnc.maxFramerate ? 1 : -1;
        }
        return 0;
    });
}
exports.sortPresets = sortPresets;
//# sourceMappingURL=publishUtils.js.map